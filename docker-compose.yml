services:
  airflow:
    build: ./airflow
    container_name: airflow_multiple_files
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__EXECUTOR: "LocalExecutor"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://postgres:postgres@postgres:5432/data_ingestion"
      AIRFLOW__LOGGING__REMOTE_LOGGING: "False"
    ports:
      - "8082:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./dbt/dbt_meds:/opt/airflow/dbt
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock

    command: >
      bash -c "
        airflow db migrate &&
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin &&
        airflow connections add 'postgres_default' --conn-uri 'postgresql+psycopg2://postgres:postgres@postgres:5432/data_ingestion' &&
        (airflow scheduler & airflow webserver)
      "
    healthcheck:
      test: [ "CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]" ]
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - airpost

  postgres:
    image: postgres:15
    restart: always
    container_name: Postgres_multiple_files
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: data_ingestion
    ports:
      - "5433:5432"
    networks:
      - airpost

networks:
  airpost:
    name: airpost
    driver: bridge
